{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing binary decision trees\n",
    "[Programming assignment 2](https://www.coursera.org/learn/ml-classification/supplement/seWHJ/implementing-binary-decision-trees) of *Machine Learning: Classification* by University of Washington on Coursera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "loans = pd.read_csv('../Data/lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  reassign the labels to have +1 for a safe loan, and -1 for a risky (bad) loan\n",
    "loans['safe_loans'] = loans['bad_loans'].map({0: +1, 1: -1})\n",
    "loans.drop('bad_loans', axis=1)\n",
    "# consider four features\n",
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "# extract these columns from the dataset and discard others\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "By one-hot encoding, we have only numeric features. In this case, each encoded feature is either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122607, 26)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.get_dummies(loans)\n",
    "loans.head(5)\n",
    "print(loans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## balance the two classes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (37224, 26) . \n",
      "Value counts: \n",
      "  1    18748\n",
      "-1    18476\n",
      "Name: safe_loans, dtype: int64\n",
      "test shape:  (9284, 26) -1    4674\n",
      " 1    4610\n",
      "Name: safe_loans, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# the train and test set index\n",
    "import json\n",
    "train_idx_file = '../data/module-5-assignment-2-train-idx.json'\n",
    "test_idx_file = '../data/module-5-assignment-2-test-idx.json'\n",
    "with open(train_idx_file) as f:\n",
    "    train_idx = json.load(f)\n",
    "with open(test_idx_file) as f:\n",
    "    test_idx = json.load(f)\n",
    "train_data = loans.iloc[train_idx, :]\n",
    "test_data = loans.iloc[test_idx, :]\n",
    "print('train shape: ', train_data.shape, '. \\nValue counts: \\n', train_data['safe_loans'].value_counts())\n",
    "print('test shape: ', test_data.shape, test_data['safe_loans'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ã€‚Implement a binary decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to count number of mistakes while predicting majority class\n",
    "In each intermediate node, we label it with the majority class. Then, the misclassification rate can be calculated. This is used to determine the best feature for splitting.\n",
    "\n",
    "**Note:** Keep in mind that in order to compute the number of mistakes for a majority classifier, we only need the label (y values) of the data points in the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    num_safe_loans = np.count_nonzero(labels_in_node == 1)\n",
    "    num_risky_loans = np.count_nonzero(labels_in_node == -1)\n",
    "    return num_risky_loans if num_safe_loans > num_risky_loans else num_safe_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# test case 1\n",
    "example_labels = np.array([-1, -1, 1, -1, -1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 1:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 1 failed... try again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# test case 2\n",
    "example_labels = np.array([-1, -1, 1, 1, 1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 1 failed... try again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "example_labels = np.array([-1, -1, -1, -1, -1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 1 failed... try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to pick best feature to split on\n",
    "The function will loop through the list of possible features, and consider splitting on each of them. It will calculate the classification error of each split and return the feature that had the smallest classification error when split on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    best_feature = None\n",
    "    min_mistakes = float('Inf')\n",
    "    for feature in features:\n",
    "        # split into two subsets: left for 0 and right for 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        # number of misclassifications\n",
    "        left_mistakes = intermediate_node_num_mistakes(left_split[target])\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split[target])\n",
    "        # error rate is: (left_mistakes + right_mistakes) / number of records in data\n",
    "        # since number of records in data remains the same for this splitting, no need to compute\n",
    "        mistakes = left_mistakes + right_mistakes\n",
    "        if mistakes < min_mistakes:\n",
    "            min_mistakes = mistakes\n",
    "            best_feature = feature\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the tree\n",
    "Each node in the tree is represented as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.is_leaf = False\n",
    "        self.predication = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.splitting_feature = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a leaf node given a set of target values: majority \n",
    "def create_leaf(labels_in_node):\n",
    "    leaf = Node()\n",
    "    leaf.is_leaf = True\n",
    "    if np.count_nonzero(labels_in_node == 1) > np.count_nonzero(labels_in_node == -1):\n",
    "        leaf.predication = 1\n",
    "    else:\n",
    "        leaf.predication = -1\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive tree building stop criteria:\n",
    "+ Condition 1: all data points in the node are from the same class\n",
    "+ Condition 2: no more features available (each feature can be used for splitting once along a path in a tree)\n",
    "+ Condition 3: max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth=0, max_depth=10):\n",
    "    target_values = data[target];\n",
    "    # stop\n",
    "    # condition1: in the same class, that is, misclassification error will be zero\n",
    "    if intermediate_node_num_mistakes(target_values) == 0:\n",
    "        print('Stopping condition 1 reached.')\n",
    "        return create_leaf(target_values)\n",
    "    if len(features) == 0:\n",
    "        print('Stopping condition 2 reached.')\n",
    "        return create_leaf(target_values)\n",
    "    if current_depth >= max_depth:\n",
    "        print('Stopping condition 3 reached: max depth.')\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # find the best feature to split\n",
    "    best_feature = best_splitting_feature(data, features, target)\n",
    "    # split\n",
    "    left_split = data[data[best_feature] == 0]\n",
    "    right_split = data[data[best_feature] == 1]\n",
    "    # remove this feature from current recursion path\n",
    "    # in Python, generally do NOT change the arguments due to the reference semantics\n",
    "    remaining_features = features[:]\n",
    "    remaining_features.remove(best_feature)\n",
    "    print('Split on feature {0} into two subsets of size {1} and {2}.'.format(best_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # if the selected feature has only one value in this dataset, then either left or right_split will be empty. In this case,\n",
    "    # we will build a leaf node for this dataset.\n",
    "    if len(left_split) == 0 or len(right_split) == 0:\n",
    "        print('The chosen splitting feature has only one value in the dataset.')\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # recursion\n",
    "    node = Node()\n",
    "    node.is_leaf = False\n",
    "    node.splitting_feature = best_feature\n",
    "    node.left = decision_tree_create(left_split, features, target, current_depth + 1, max_depth)\n",
    "    node.right = decision_tree_create(right_split, features, target, current_depth + 1, max_depth)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In the above building process, when the chosen feature has only one value in the intermediate subset D, the procedure labels such an intermediate node D as a leaf. \n",
    "\n",
    "+ However, a better way is to continue the tree building: for the child whose data is empty, assign it as a leaf and its class is the majority of its parent D. For the other child whose data is not empty (actually also D), continue the building process for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-47-e71541d13fb1>\u001b[0m(7)\u001b[0;36mdecision_tree_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      5 \u001b[1;33m    \u001b[1;31m# stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6 \u001b[1;33m    \u001b[1;31m# condition1: in the same class, that is, misclassification error will be zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 7 \u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0mintermediate_node_num_mistakes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping condition 1 reached.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[1;32m<ipython-input-47-e71541d13fb1>\u001b[0m(10)\u001b[0;36mdecision_tree_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      8 \u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping condition 1 reached.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 10 \u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     11 \u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping condition 2 reached.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> len(features)\n",
      "25\n",
      "ipdb> n\n",
      "> \u001b[1;32m<ipython-input-47-e71541d13fb1>\u001b[0m(13)\u001b[0;36mdecision_tree_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     11 \u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping condition 2 reached.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 13 \u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0mcurrent_depth\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     14 \u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping condition 3 reached: max depth.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     15 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "Split on feature term_ 36 months into two subsets of size 9223 and 28001.\n",
      "> \u001b[1;32m<ipython-input-47-e71541d13fb1>\u001b[0m(7)\u001b[0;36mdecision_tree_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      5 \u001b[1;33m    \u001b[1;31m# stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6 \u001b[1;33m    \u001b[1;31m# condition1: in the same class, that is, misclassification error will be zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 7 \u001b[1;33m    \u001b[1;32mif\u001b[0m \u001b[0mintermediate_node_num_mistakes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping condition 1 reached.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n",
      "Exiting Debugger.\n"
     ]
    }
   ],
   "source": [
    "# build the tree\n",
    "features = list(train_data) # equivalent to my_dataframe.columns.values.tolist()\n",
    "features.remove(target)\n",
    "tree = decision_tree_create(train_data, features, target, 0, max_depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predication\n",
    "Just preorder traversal of a binary tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate=False):\n",
    "    if tree.is_leaf:\n",
    "        if annotate:\n",
    "            print('At leaf, predicting {}'.format(tree.predication))\n",
    "        return tree.predication\n",
    "    # goto the left or right subtree depending on the feature value\n",
    "    split_feature_value = x[tree.splitting_feature]\n",
    "    if annotate:\n",
    "        print('Split on {} = {}'.format(tree.splitting_feature, split_feature_value))\n",
    "    if split_feature_value == 0:\n",
    "        return classify(tree.left, x, annotate)\n",
    "    else:\n",
    "        return classify(tree.right, x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe_loans                -1\n",
      "grade_A                    0\n",
      "grade_B                    0\n",
      "grade_C                    0\n",
      "grade_D                    1\n",
      "grade_E                    0\n",
      "grade_F                    0\n",
      "grade_G                    0\n",
      "term_ 36 months            0\n",
      "term_ 60 months            1\n",
      "home_ownership_MORTGAGE    0\n",
      "home_ownership_OTHER       0\n",
      "home_ownership_OWN         0\n",
      "home_ownership_RENT        1\n",
      "emp_length_1 year          0\n",
      "emp_length_10+ years       0\n",
      "emp_length_2 years         1\n",
      "emp_length_3 years         0\n",
      "emp_length_4 years         0\n",
      "emp_length_5 years         0\n",
      "emp_length_6 years         0\n",
      "emp_length_7 years         0\n",
      "emp_length_8 years         0\n",
      "emp_length_9 years         0\n",
      "emp_length_< 1 year        0\n",
      "emp_length_n/a             0\n",
      "Name: 24, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# a simple test\n",
    "x = test_data.iloc[0, :]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term_ 36 months = 0\n",
      "Split on grade_A = 0\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(tree, x, annotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    predications = data.apply(lambda record: classify(tree, record), axis=1) # apply to each row\n",
    "    return (predications != data[target]).sum() / len(predications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38377854373115039"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(tree, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'term_ 36 months'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.splitting_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
